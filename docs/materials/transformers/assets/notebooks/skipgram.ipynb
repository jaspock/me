{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thlU7qzxespH"
      },
      "source": [
        "# Skip-gram model to obtain context-free word embeddings\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/jaspock/me/blob/main/docs/materials/transformers/assets/notebooks/skipgram.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Code written by Juan Antonio PÃ©rez in 2024. Originally inspired on the Tae Hwan Jung's code (@graykode) at the [NLP tutorial](https://github.com/graykode/nlp-tutorial).\n",
        "\n",
        "This notebook presents the implementation of a skip-gram model to obtain non-contextual word embeddings       . The conceptual framework that we need to implement this model is so similar to the one used in the notebooks implementing logistic and softmax regressors that most of your effort will be spent in understanding the process of obtaining the data or representing the embeddings, more than in PyTorch code itself. As you will see, the skip-gram model is a particular case of a logistic regressor where the output is the probability of a word being a context word of another word, that is, the probability of two words being close neighbors in a text.\n",
        "\n",
        "Our softmax regressor dealing with topic classification required each input sentence to be encoded as an embedding vector. As it was too early to talk about embeddings, we used a library (`sentence-transformers`) to obtain them in a black-box fashion. Here we will see how to get an embedding for every word in a text, not for every sentence. However, it turns out that, although there exist more elaborated methods to obtain sentence embeddings, one the simplest ones is to average the embeddings of the words in the sentence. Consequently, this notebook could also be easily adapted to implement a very rudimentary version of the `sentence-transformers` library.\n",
        "\n",
        "**Question**: Integrate this code and the code of the softmax regressor to have a self-contained version of the sentence topic classifier that does not depend on external libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (2.1.2)\n",
            "Requirement already satisfied: transformers in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (4.36.2)\n",
            "Requirement already satisfied: matplotlib in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (3.8.2)\n",
            "Requirement already satisfied: filelock in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (2023.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "torch.random.manual_seed(22)\n",
        "random.seed(22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing\n",
        "\n",
        "We start with the code that obtains the data that will be later packed into mini-batches. Following the algorithm, each mini-batch contains positive and negative samples in a 1:$k$ ratio. To obatin the positive samples, we iterate over the corpus word by word. For each *target* word, we obtain the context words within a window of size $L$. As allowing different values of $L$ would slightly complicate the implementation, we simply set $L=1$ and consider only the *context* words before and after the target word. To obtain the negative samples, we combine the target word and sample noise words from the vocabulary. The Martin and Jurafsky's book explains that these noise words are chosen based on their unigram frequency, but we will also simplify here and choose them uniformly at random.\n",
        "\n",
        "We usually use a large text file to train the skip-gram model. For the sake of simplicity, we use a toy dataset stored in a single string in which each sentence contains a few words and two noticeable domains, namely, fruits and animals, can be found. Sometimes, a word of one of the domains occurs in the context of a sentence of the other domain.\n",
        "\n",
        "Observe how the period at the end of each sentence is considered as a word. Separating the period from the last word of the sentence, we make sure that \"uva\" and \"uva.\" are not considered as different words. We also lowercase all the words to avoid having different embeddings for the same word in different cases (\"Manzana\" and \"manzana\", for example). Although this preprocessing was frequent in the past, it is not common anymore in current real-world applications due to the large scale of the datasets and training procedures. This is a first example of how we will not process only words; actually, the more general word *token* will be used to refer to the atomic elements of the vocabulary. As we will see, tokens can be words, but also subwords, characters, punctuation marks, emojis, or even the bytes which make up the different characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = \"\"\"\n",
        "    perro gato ratÃ³n pÃ¡jaro .\n",
        "    manzana naranja pera uva .\n",
        "    azul rojo verde amarillo .\n",
        "    guitarra piano violÃ­n flauta .\n",
        "    perro gato .\n",
        "    uva pera manzana .\n",
        "    amarillo rojo .\n",
        "    piano violÃ­n .\n",
        "    ratÃ³n pÃ¡jaro gato .\n",
        "    verde azul amarillo uva .\n",
        "    perro .\n",
        "    naranja .\n",
        "    azul piano verde .\n",
        "    flauta guitarra .\n",
        "    gato ratÃ³n perro .\n",
        "    manzana naranja uva pera .\n",
        "    rojo amarillo azul .\n",
        "    violÃ­n piano flauta .\n",
        "    pÃ¡jaro ratÃ³n gato perro .\n",
        "    uva manzana naranja .\n",
        "    verde azul .\n",
        "    guitarra violÃ­n piano .\n",
        "    perro pÃ¡jaro .\n",
        "    pera uva manzana naranja .\n",
        "    amarillo verde rojo azul .\n",
        "    flauta piano .\n",
        "    gato ratÃ³n pÃ¡jaro .\n",
        "    naranja uva manzana pera .\n",
        "    azul rojo verde .\n",
        "    violÃ­n flauta guitarra piano .\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following lines are common boilerplate code to obtain the vocabulary in the form of word-to-index and index-to-word dictionaries. Note that our corpus is first transformed into a list of words. Also note that we keep the whole corpus in memory, which is not a problem for this toy dataset but would be for a large corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word_dict = {'naranja': 0, 'violÃ­n': 1, 'azul': 2, 'rojo': 3, 'gato': 4, '.': 5, 'piano': 6, 'guitarra': 7, 'uva': 8, 'flauta': 9, 'perro': 10, 'pera': 11, 'pÃ¡jaro': 12, 'ratÃ³n': 13, 'verde': 14, 'amarillo': 15, 'manzana': 16}\n",
            "dict_word = {0: 'naranja', 1: 'violÃ­n', 2: 'azul', 3: 'rojo', 4: 'gato', 5: '.', 6: 'piano', 7: 'guitarra', 8: 'uva', 9: 'flauta', 10: 'perro', 11: 'pera', 12: 'pÃ¡jaro', 13: 'ratÃ³n', 14: 'verde', 15: 'amarillo', 16: 'manzana'}\n",
            "voc_size = 17\n"
          ]
        }
      ],
      "source": [
        "corpus = corpus.split()  # split by space\n",
        "word_list = list(set(corpus))  # removes duplicates\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}  # word from index\n",
        "dict_word = {i: w for i, w in enumerate(word_list)}  # index from word\n",
        "voc_size = len(word_list)  # number of words\n",
        "\n",
        "print(f\"word_dict = {word_dict}\")\n",
        "print(f\"dict_word = {dict_word}\")\n",
        "print(f\"voc_size = {voc_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create now two lists, one for the positive samples and one for the negative samples. Each list item contains the index of the target word and the index of the context word or the noise word, respectively. Recall that our context window for positive samples will be of size 1 and that we will use a 1:$k$ ratio between positive and negative samples.\n",
        "\n",
        "We iterate over the corpus word by word starting at index 1 and ending at index `len(corpus)-1` to avoid considering the first and last words of the corpus as target words, as this would require special treatment due to the lack of context words before and after them, respectively.\n",
        "\n",
        "It is not strictly necessary at this point to create $k$ times more negative samples than positive samples, as the value of $k$ in the algorithm determines the ratio of negative samples in each mini-batch. However, it makes sense to create more negative samples than positive samples to avoid having to repeat a reduced set of negative samples over and over again in the mini-batches.\n",
        "\n",
        "**Documentation:** [random.sample](https://docs.python.org/3/library/random.html#random.sample)\n",
        "\n",
        "**Question:** Adapt the code so that different window sizes can be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some positive samples: [[4, 10], [4, 13], [13, 4]]\n",
            "Some negative samples: [[10, 11], [10, 1], [4, 14]]\n",
            "Some positive samples with tokens: (gato,perro), (gato,ratÃ³n), (ratÃ³n,gato)\n",
            "Some negative samples with tokens: (perro,pera), (perro,violÃ­n), (gato,verde)\n"
          ]
        }
      ],
      "source": [
        "k = 2  # ratio of negative samples to positive samples\n",
        "\n",
        "skip_grams_positive = []\n",
        "for i in range(1, len(corpus) - 1):\n",
        "    target = word_dict[corpus[i]]\n",
        "    context = [word_dict[corpus[i - 1]], word_dict[corpus[i + 1]]]\n",
        "    for c in context:\n",
        "        skip_grams_positive.append([target, c])\n",
        "\n",
        "skip_grams_negative = []\n",
        "for i in range(len(corpus)):\n",
        "    target = word_dict[corpus[i]]\n",
        "    context = [word_dict[i] for i in random.sample(word_list,k)]\n",
        "    for c in context:\n",
        "        skip_grams_negative.append([target, c])\n",
        "\n",
        "print(f\"Some positive samples: {skip_grams_positive[:3]}\")\n",
        "print(f\"Some negative samples: {skip_grams_negative[:3]}\")\n",
        "print(f\"Some positive samples with tokens: {', '.join([f'({dict_word[i[0]]},{dict_word[i[1]]})' for i in skip_grams_positive[:3]])}\")\n",
        "print(f\"Some negative samples with tokens: {', '.join([f'({dict_word[i[0]]},{dict_word[i[1]]})' for i in skip_grams_negative[:3]])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini-batch generation\n",
        "\n",
        "It's time to define the function that returns a mini-batch of positive and negative samples. The function receives as input the `skip_grams_positive` and `skip_grams_negative` lists and the size of the mini-batch. It returns a tuple containing the indices of the target words, the indices of the context/noise words and the labels of the samples. The labels are 1 for positive samples and 0 for negative samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_batch(skip_grams_positive, skip_grams_negative, batch_size):\n",
        "    random_target = []\n",
        "    random_context= []\n",
        "    random_output = []\n",
        "\n",
        "    positive_size = batch_size//(k+1)\n",
        "\n",
        "    random_index = np.random.choice(range(len(skip_grams_positive)), positive_size, replace=True)\n",
        "    for i in random_index:\n",
        "        random_target.append(skip_grams_positive[i][0])\n",
        "        random_context.append(skip_grams_positive[i][1])\n",
        "        random_output.append(1)  # desired output = 1\n",
        "\n",
        "    random_index = np.random.choice(range(len(skip_grams_negative)), positive_size*k, replace=True)\n",
        "    for i in random_index:\n",
        "        random_target.append(skip_grams_negative[i][0])\n",
        "        random_context.append(skip_grams_negative[i][1])\n",
        "        random_output.append(0)  # desired output = 0 \n",
        "\n",
        "    return random_target, random_context, random_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model definition\n",
        "\n",
        "We have already implemented some PyTorch models by now, so you should be familiar with the basic ideas of the following code. There are, however, some new additions.\n",
        "\n",
        "The `Word2Vec` class extends PyTorch's `nn.Module`. The constructor method `__init__` is responsible for initializing the model's layers and other components. In this class, two embedding layers are created and randomly initialized: `self.W` and `self.C`. Both are instances of PyTorch's `nn.Embedding` class, which is used to store word embeddings. The `nn.Embedding` layer is a lookup table that maps the index of a word to its embedding vector. The embedding vectors are the parameters of the layer and are updated during training. The `nn.Embedding` layer is a particular case of the `nn.Linear` layer, which we have already used. As most of the functions in PyTorch, `nn.Embedding` expects a mini-batch of word indices as input and not a single word index. It then returns a mini-batch of embedding vectors. The `voc_size` parameter specifies the size of the vocabulary, whereas the `embedding_size` parameter sets the size of each embedding vector. In essence, `self.W` serves as the embedding matrix for target words, while `self.C` is for context words in the training data.\n",
        "\n",
        "The `forward` method defines the computation performed at every call of the model. It takes two arguments, `Xt` and `Xc`, which are the input tensors for target words and context/noise words, both of size `(batch_size, 1)`. The method uses the embedding layers to transform these input word indices into dense embedding vectors.\n",
        "\n",
        "### Einstein summation notation\n",
        "\n",
        "The most critical operation is `torch.einsum` which we describe next. You may find from time to time that some operations that you would like to perform are not available in PyTorch. In these cases, you can use `torch.einsum` to perform tensor operations with Einstein summation notation. This function is a powerful tool that allows for concise and efficient computation of complex tensor algebra.\n",
        "\n",
        "Let's consider the case where we have a mini-batch of target words represented by their embeddings $\\mathbf{w}_1,\\mathbf{w}_2,\\ldots,\\mathbf{w}_E$. For each of these target words, we have an associated contextual word in the set $\\mathbf{c}_1,\\mathbf{c}_2,\\ldots,\\mathbf{c}_E$. To simplify, let's not consider negative samples, but this analysis is fully extendable to the case where they are included.\n",
        "\n",
        "Let $N$ be the size of the embeddings. We want to calculate the dot product of each $\\mathbf{w}_i$ with its corresponding $\\mathbf{c}_i$, a calculation fundamental in the training and use of skip-gram models. To obtain these dot products using PyTorch and benefit from the efficiency of matrix operations computed on GPUs, we can pack the embeddings of the target words by rows into a matrix $A$ of size $E \\times N$ and the embeddings of the contextual words by columns into a matrix $B$ of size $N \\times E$. By calculating the product $A \\cdot B$, we will obtain a matrix of size $E \\times E$ where each element $i,j$ is the dot product of $\\mathbf{w}_i$ with $\\mathbf{c}_j$. \n",
        "\n",
        "However, we are only interested in a small part of all these dot products. Specifically, those that form part of the diagonal of the result, which will be the ones of the form $\\mathbf{w}_i$ $\\mathbf{c}_i$. Matrix multiplication is very inefficient in this case for our purposes, but if we look in the PyTorch documentation, we will not initially find an operation that fits exactly to our interests.\n",
        "\n",
        "There is, however, in PyTorch an efficient and compact way to define matrix operations based on Einstein's notation, which you can learn a little about by reading up to approximately section 2.8 of the tutorial \"[Einsum is all you need](https://rockt.github.io/2018/04/30/einsum)\". In particular, we can see that we are interested in obtaining a vector $\\mathbf{d}$ such that:\n",
        "\n",
        "$$\n",
        "\\mathbf{d}_i = \\mathbf{w}_i \\cdot \\mathbf{c}_i = \\sum_{j} \\mathbf{w}_{i,j} \\, \\mathbf{c}_{j,i}\n",
        "$$\n",
        "\n",
        "Using Einstein's notation with PyTorch's `einsum` function, we can write the previous matrix operation and obtain the one-dimensional tensor we want as\n",
        "\n",
        "    d = torch.einsum('ij,ji->i', A, B)\n",
        "\n",
        "**Question:** Rewrite the Einstein notation in the code to avoid the transposition of the matrix $c$.\n",
        "\n",
        "**TODO:** copy all discussions on Pytorch stuff from teacher's notes; add seeds in every notebook; use GPU if available in every notebook; difference between F.sigmoid and torch.sigmoid; move epoch to steps; move word_dict and dict_word to word_index and index_word; add model.train() and eval()\n",
        "\n",
        "**Documentation:** [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [torch.nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html), [torch.einsum](https://pytorch.org/docs/stable/generated/torch.einsum.html), [torch.sigmoid](https://pytorch.org/docs/stable/generated/torch.sigmoid.html), [torch.t](https://pytorch.org/docs/stable/generated/torch.t.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Model\n",
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, voc_size, embedding_size):\n",
        "        super().__init__()\n",
        "        self.W = nn.Embedding(voc_size, embedding_size)  # target matrix \n",
        "        self.C = nn.Embedding(voc_size, embedding_size)  # context matrix\n",
        "\n",
        "    def forward(self, Xt, Xc):\n",
        "        w = self.W(Xt)  \n",
        "        c = self.C(Xc)\n",
        "        dot = torch.einsum('ij,ji->i',w,c.t())\n",
        "        output_layer = F.sigmoid(dot)\n",
        "        return output_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the model\n",
        "\n",
        "Training the model is straightforward given the code we have already seen in previous notebooks. We use the `Adam` optimizer and the `BCELoss` (binary cross-entropy) loss function. The main novelty is that the lists of indices returned by `random_batch` are converted into PyTorch tensors of long integers (`torch.long`) before being passed to the model. This is because PyTorch expects the indices of the embedding layer to be of this type. Note, however, that `BCELoss` expects the labels to be floating-point numbers (`torch.float32`). The remaining code is very similar to what we have seen before.\n",
        "\n",
        "**Exercise:** Adapt the code to use the `SGD` optimizer instead of `Adam` and compare the results in 3 different training runs.\n",
        "\n",
        "**Documentation:** [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html), [torch.nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html), [torch.Tensor.to](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to), [torch.optim.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html), [torch.Tensor.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html), [torch.optim.step](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000, cost=0.454811\n",
            "Epoch: 2000, cost=0.468414\n",
            "Epoch: 3000, cost=0.459508\n",
            "Epoch: 4000, cost=0.432788\n",
            "Epoch: 5000, cost=0.526175\n",
            "Epoch: 6000, cost=0.445378\n",
            "Epoch: 7000, cost=0.432225\n",
            "Epoch: 8000, cost=0.432305\n",
            "Epoch: 9000, cost=0.432573\n",
            "Epoch: 10000, cost=0.433031\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "batch_size = 256\n",
        "embedding_size = 2\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = Word2Vec(voc_size, embedding_size).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "# model.parameters(): iterable with all parameters of the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    input_w_batch, input_c_batch, target_batch = random_batch(skip_grams_positive, skip_grams_negative, batch_size)\n",
        "    input_w_batch = torch.tensor(input_w_batch,dtype=torch.long).to(device)\n",
        "    input_c_batch = torch.tensor(input_c_batch,dtype=torch.long).to(device)\n",
        "    target_batch = torch.tensor(target_batch,dtype=torch.float32).to(device) \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_w_batch,input_c_batch)\n",
        "\n",
        "    # output : [batch_size], target_batch : [batch_size]\n",
        "    loss = criterion(output, target_batch)\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f'Epoch: {(epoch+1):04d}, cost={loss:.6f}')\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the embeddings\n",
        "\n",
        "The parameters of the model are unpacked into tensors `W` and `C`. The `W` tensor contains the embeddings of the target words, whereas the `C` tensor contains the embeddings of the context words.\n",
        "\n",
        "We will represent the embeddings of `W` in a two-dimensional space. To do so, the two dimensions of each embedding are unpacked into the `x` and `y` variables which are then plotted via `plt.scatter`. The `plt.annotate` function is used to add the word labels to the plot. Knowing most of the arguments of this function is out of the scope of this notebook, but you can find more information in the documentation.\n",
        "\n",
        "**Exercise:** Adapt the code to plot the embeddings of `C` instead of `W`, as well as the average of the embeddings of `W` and `C`.\n",
        "\n",
        "**Documentation:** [matplotlib.pyplot.scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html), [matplotlib.pyplot.annotate](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))  # square figure\n",
        "for i, label in enumerate(word_list):\n",
        "    W, C = model.parameters()  # W, _ = model.parameters() would be more appropriate\n",
        "    x, y = W[i][0].item(), W[i][1].item()\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the similarity between words\n",
        "\n",
        "The resulting similarity between two words can be measured by the cosine similarity between their embeddings. See, for example, how the similarity between \"uva\" and \"manzana\" is higher than the similarity between \"uva\" and \"gato\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cos = nn.CosineSimilarity(dim=0) # works on dim=1 by default (a batch of tensors, but there is only dim=0 in our case)\n",
        "\n",
        "print(f\"Cosine similarity between 'uva' and 'manzana' is {cos(model.W[word_dict['uva']], model.W[word_dict['manzana']]).item():.3f}\")\n",
        "print(f\"Cosine similarity between 'uva' and 'gato' is {cos(model.W[word_dict['uva']], model.W[word_dict['gato']]).item():.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
