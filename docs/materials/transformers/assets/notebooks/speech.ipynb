{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: torch==2.1.2 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torchaudio) (2.1.2)\n",
      "Requirement already satisfied: filelock in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from torch==2.1.2->torchaudio) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchaudio) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from jinja2->torch==2.1.2->torchaudio) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/japerez/miniconda3/envs/tpln/lib/python3.9/site-packages (from sympy->torch==2.1.2->torchaudio) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train-clean-100.tar.gz.93eeaaa58928468691351a0aad2b90ce.partial'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m29\u001b[39m  \u001b[38;5;66;03m# 26 letras + espacio, apóstrofe y caracter en blanco\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Conjuntos de datos y cargadores\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mLIBRISPEECH\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain-clean-100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m LIBRISPEECH(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest-clean\u001b[39m\u001b[38;5;124m\"\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mdata_processing)\n",
      "File \u001b[0;32m~/miniconda3/envs/tpln/lib/python3.9/site-packages/torchaudio/datasets/librispeech.py:113\u001b[0m, in \u001b[0;36mLIBRISPEECH.__init__\u001b[0;34m(self, root, url, folder_in_archive, download)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path):\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 113\u001b[0m         \u001b[43m_download_librispeech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please set `download=True` to download the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/tpln/lib/python3.9/site-packages/torchaudio/datasets/librispeech.py:42\u001b[0m, in \u001b[0;36m_download_librispeech\u001b[0;34m(root, url)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(archive):\n\u001b[1;32m     41\u001b[0m     checksum \u001b[38;5;241m=\u001b[39m _CHECKSUMS\u001b[38;5;241m.\u001b[39mget(download_url, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m _extract_tar(archive)\n",
      "File \u001b[0;32m~/miniconda3/envs/tpln/lib/python3.9/site-packages/torch/hub.py:638\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    636\u001b[0m tmp_dst \u001b[38;5;241m=\u001b[39m dst \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.partial\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtmp_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train-clean-100.tar.gz.93eeaaa58928468691351a0aad2b90ce.partial'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from torch.nn import Module, Conv2d, Linear, TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definición del modelo\n",
    "class SpeechRecognitionModel(Module):\n",
    "    def __init__(self, num_classes, input_size=128, num_heads=4, num_layers=3, hidden_size=256):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        # Capas convolucionales para reducir la dimensionalidad\n",
    "        self.conv1 = Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2))\n",
    "        self.conv2 = Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "\n",
    "        # Transformer para el procesamiento secuencial\n",
    "        transformer_layer = TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size)\n",
    "        self.transformer_encoder = TransformerEncoder(transformer_layer, num_layers=num_layers)\n",
    "\n",
    "        # Capa lineal para el mapeo a la salida\n",
    "        self.fc = Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.permute(2, 0, 1)  # Cambiar a formato (seq_len, batch, features)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Cargar y procesar datos\n",
    "def data_processing(data):\n",
    "    spectrogram_transform = MelSpectrogram()\n",
    "    waveform, _, utterances, _, _, _ = zip(*data)\n",
    "    spectrograms = [spectrogram_transform(w).squeeze(0).transpose(0, 1) for w in waveform]\n",
    "    input_lengths = [len(s) for s in spectrograms]\n",
    "    target_lengths = [len(u) for u in utterances]\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    targets = [torch.tensor([ord(c) for c in u]) for u in utterances]\n",
    "    targets = nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
    "    return spectrograms, targets, input_lengths, target_lengths\n",
    "\n",
    "# Configuración\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "num_classes = 29  # 26 letras + espacio, apóstrofe y caracter en blanco\n",
    "\n",
    "# Conjuntos de datos y cargadores\n",
    "train_dataset = LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=True)\n",
    "test_dataset = LIBRISPEECH(\"./data\", url=\"test-clean\", download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_processing)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_processing)\n",
    "\n",
    "# Instanciar modelo y optimizador\n",
    "model = SpeechRecognitionModel(num_classes=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CTCLoss(blank=28, zero_infinity=True)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (spectrograms, targets, input_lengths, target_lengths) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = output.permute(1, 0, 2)  # Reordenar a (time, batch, n_class)\n",
    "            loss = criterion(output, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')\n",
    "\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Función para visualizar espectrograma\n",
    "def plot_spectrogram(spectrogram):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(spectrogram.log2(), aspect='auto', origin='lower', \n",
    "               cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Reproducir un archivo de audio\n",
    "def play_audio(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "\n",
    "# Prueba de visualización y reproducción de un archivo\n",
    "test_audio_path = \"./data/LibriSpeech/test-clean/1089/134686/1089-134686-0000.flac\"\n",
    "waveform, sample_rate = torchaudio.load(test_audio_path)\n",
    "spectrogram = MelSpectrogram()(waveform)\n",
    "plot_spectrogram(spectrogram[0])\n",
    "play_audio(test_audio_path)\n",
    "\n",
    "# Evaluación del modelo con un solo archivo de audio\n",
    "def evaluate(model, audio_path):\n",
    "    model.eval()\n",
    "    waveform, _ = torchaudio.load(audio_path)\n",
    "    spectrogram = MelSpectrogram()(waveform).unsqueeze(0).transpose(2, 3)\n",
    "    with torch.no_grad():\n",
    "        output = model(spectrogram)\n",
    "        output = output.permute(1, 0, 2)  # Reordenar a (time, batch, n_class)\n",
    "        output = torch.argmax(output, dim=2)\n",
    "        output = output.transpose(0, 1).squeeze(0)\n",
    "        return ''.join([chr(o + 96) for o in output if o != 28])  # Convertir a texto\n",
    "\n",
    "# Uso de evaluate para probar un archivo\n",
    "print(evaluate(model, test_audio_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
